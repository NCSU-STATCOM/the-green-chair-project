# Exploring TGCP data

We have spent a lot of time cleaning the data, allowing us to start making visualizations.
First, we wanted to answer how many clients are living below the 30% median income line, how many are in the 30% and 60% range, and how many are above the 60% range. 
It's important to note that the thresholds for these classifcations change both by year and by the number of people that live in a household.
[**\textcolor{blue}{You can see the thresholds for 2021 here, provided by the HOME Investment Partnerships Program.}**](https://www.huduser.gov/portal/datasets/home-datasets/files/HOME_IncomeLmts_State_NC_2021.pdf)
Note that we are using the threshold for Raleigh.
With all that in mind, we have categorized each client/family as being below the 30% line, between 30% and 60%, above 60%, or unknown (if the income data was unavailable).


```{r child = 'tgcp-data/median_income_bar_plots.Rmd', echo = FALSE, message = FALSE, warning = FALSE}
```

\newpage

We have also looked at the total number of beds provided to clients (number of twins and queens combined).
Again, since this may changed based on the number of members of a household, we have stratified.

```{r child = 'Long Format Data set/beds_by_people.Rmd', echo = FALSE, message = FALSE, warning = FALSE}
```

\newpage

Next we wanted to investigate which agencies refered the most clients.
From this, we can get a better grasp on where the clients are coming from and how to best serve them.
These are the ten agencies that refer the most clients. 

```{r, echo=FALSE, message = FALSE, warning = FALSE}
## Common Agencies

# Setting up
library(readxl)
library(writexl)
library(tidyverse)

# Read in raw data
tgcp_demog <- read_excel("STATCOM_data.xlsx", col_types = "text")
tgcp_demog <- rename(tgcp_demog, Id = `...1`)

# Viewing the data
#View(tail(tgcp_demog[, c(1:40, 119:128)], n = 100))

# List of Agencies -- needs to be cleaned
#ggplot(data = tgcp_demog, aes(x = Agency)) + geom_histogram(stat = "count")
agency_table <- as.data.frame(table(tgcp_demog$Agency))
colnames(agency_table) <- c("Agency","Freq")
# View(agency_table)

# Write to spreadsheet for data cleaning
# write_xlsx(agency_table, 
          # "C:\\Users\\shakt\\OneDrive\\Documents\\NC State\\TGCP\\the green chair project\\AgencyNames.xlsx")

# Reading in new spreadsheet with duplicate rows for cleaned names
agency_clean <- read_excel("AgencyNames.xlsx", range = cell_cols("B:D"))
# View(agency_clean)

# Aggregating duplicate rows to update frequency count
agency_clean2 <- aggregate(Freq~Agency_Clean_Short, 
                           data = agency_clean, FUN=sum)

## Visualizing the agency data
# Not very useful plot (too many variables)
#ggplot(data = agency_clean, aes(x = Agency_Clean_Short)) + geom_bar()

# Top 10 Agencies only
agency_clean2 %>% arrange(desc(Freq)) %>%
  slice(1:10) %>%
  mutate(agency_rank = fct_reorder(Agency_Clean_Short, Freq),
         highlight =
           ifelse(Agency_Clean_Short %in%
                              Agency_Clean_Short[which.max(Freq)],T,F)) %>%
  ggplot(., aes(x=factor(agency_rank),y=Freq)) +
  # geom_bar(stat = 'identity', aes(fill=highlight)) +
  # scale_fill_manual(values = c("grey50","#6BBF4E")) +
    geom_bar(stat = 'identity') +
  coord_flip() +
  theme(axis.text.y = element_text(size = 7, angle = 45),
        legend.position = "none") +
  labs(title = "Top 10 Agencies",
       x = "", y = "") 

```

As expected, the Wake Country Public School System was referred the most by far, with nearly 1200 referrals. 
This has encouraged us to look further into the schools (see chapter 4).
